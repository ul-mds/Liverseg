[2024-08-01 16:03:21,848][flwr][INFO] - Starting Flower simulation, config: num_rounds=15, no round_timeout
[2024-08-01 16:03:24,546][flwr][INFO] - Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'node:10.50.9.88': 1.0, 'object_store_memory': 35757125222.0, 'memory': 73433292186.0, 'CPU': 8.0, 'accelerator_type:T4': 1.0, 'node:__internal_head__': 1.0}
[2024-08-01 16:03:24,546][flwr][INFO] - Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html
[2024-08-01 16:03:24,546][flwr][INFO] - Flower VCE: Resources for each Virtual Client: {'num_cpus': 3, 'num_gpus': 0.0}
[2024-08-01 16:03:24,559][flwr][INFO] - Flower VCE: Creating VirtualClientEngineActorPool with 2 actors
[2024-08-01 16:03:24,560][flwr][INFO] - [INIT]
[2024-08-01 16:03:24,560][flwr][INFO] - Requesting initial parameters from one random client
[2024-08-01 16:03:27,734][flwr][INFO] - Received initial parameters from one random client
[2024-08-01 16:03:27,734][flwr][INFO] - Evaluating initial global parameters
[2024-08-01 16:08:42,113][flwr][INFO] - initial parameters (loss, other metrics): 0.6928816641819884, OrderedDict([('ind_iou_0', 0.09076302503225273), ('ind_dice_liver_0', tensor(0.1533, dtype=torch.float64)), ('ind_dice_tumour_0', tensor(0.0093, dtype=torch.float64)), ('ind_iou_1', 0.09148529098738986), ('ind_dice_liver_1', tensor(0.1545, dtype=torch.float64)), ('ind_dice_tumour_1', tensor(0.0081, dtype=torch.float64)), ('all_iou', 0.09084252793964295), ('all_dice_liver', tensor(0.1534, dtype=torch.float64)), ('all_dice_tumour', tensor(0.0092, dtype=torch.float64))])
[2024-08-01 16:08:42,118][flwr][INFO] - 
[2024-08-01 16:08:42,118][flwr][INFO] - [ROUND 1]
[2024-08-01 16:08:42,118][flwr][INFO] - configure_fit: strategy sampled 2 clients (out of 2)
[2024-08-01 16:08:42,472][flwr][ERROR] - Traceback (most recent call last):
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 73, in _submit_job
    out_mssg, updated_context = self.actor_pool.get_client_result(
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 399, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 280, in _fetch_future_result
    res_cid, out_mssg, updated_context = ray.get(
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ClientAppException): [36mray::ClientAppActor.run()[39m (pid=2974414, ip=10.50.9.88, actor_id=405536d3804c61353323fd1901000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7f8d385236a0>)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/client/client_app.py", line 98, in __call__
    return self._call(message, context)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/client/client_app.py", line 81, in ffn
    out_message = handle_legacy_message_from_msgtype(
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/client/message_handler/message_handler.py", line 130, in handle_legacy_message_from_msgtype
    fit_res = maybe_call_fit(
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/client/client.py", line 234, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/client/numpy_client.py", line 238, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/home/mmaia/fedliver_v2/client.py", line 65, in fit
    train(self.model,self.trainloader,self.valloader,optimizer,criterion,self.device, self.cfg.local_epochs)
  File "/home/mmaia/fedliver_v2/model/unet.py", line 163, in train
    input = input.to(device)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/torch/cuda/__init__.py", line 247, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available

The above exception was the direct cause of the following exception:

[36mray::ClientAppActor.run()[39m (pid=2974414, ip=10.50.9.88, actor_id=405536d3804c61353323fd1901000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7f8d385236a0>)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 64, in run
    raise ClientAppException(str(ex)) from ex
flwr.client.client_app.ClientAppException: 
Exception ClientAppException occurred. Message: No CUDA GPUs are available

[2024-08-01 16:08:42,473][flwr][ERROR] - [36mray::ClientAppActor.run()[39m (pid=2974414, ip=10.50.9.88, actor_id=405536d3804c61353323fd1901000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7f8d385236a0>)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/client/client_app.py", line 98, in __call__
    return self._call(message, context)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/client/client_app.py", line 81, in ffn
    out_message = handle_legacy_message_from_msgtype(
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/client/message_handler/message_handler.py", line 130, in handle_legacy_message_from_msgtype
    fit_res = maybe_call_fit(
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/client/client.py", line 234, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/client/numpy_client.py", line 238, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/home/mmaia/fedliver_v2/client.py", line 65, in fit
    train(self.model,self.trainloader,self.valloader,optimizer,criterion,self.device, self.cfg.local_epochs)
  File "/home/mmaia/fedliver_v2/model/unet.py", line 163, in train
    input = input.to(device)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/torch/cuda/__init__.py", line 247, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available

The above exception was the direct cause of the following exception:

[36mray::ClientAppActor.run()[39m (pid=2974414, ip=10.50.9.88, actor_id=405536d3804c61353323fd1901000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7f8d385236a0>)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 64, in run
    raise ClientAppException(str(ex)) from ex
flwr.client.client_app.ClientAppException: 
Exception ClientAppException occurred. Message: No CUDA GPUs are available
[2024-08-01 16:08:44,760][flwr][ERROR] - Traceback (most recent call last):
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 73, in _submit_job
    out_mssg, updated_context = self.actor_pool.get_client_result(
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 399, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 280, in _fetch_future_result
    res_cid, out_mssg, updated_context = ray.get(
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ClientAppException): [36mray::ClientAppActor.run()[39m (pid=2974413, ip=10.50.9.88, actor_id=ff978cdf80890de43561d24801000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7f7e2816c670>)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/client/client_app.py", line 98, in __call__
    return self._call(message, context)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/client/client_app.py", line 81, in ffn
    out_message = handle_legacy_message_from_msgtype(
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/client/message_handler/message_handler.py", line 130, in handle_legacy_message_from_msgtype
    fit_res = maybe_call_fit(
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/client/client.py", line 234, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/client/numpy_client.py", line 238, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/home/mmaia/fedliver_v2/client.py", line 65, in fit
    train(self.model,self.trainloader,self.valloader,optimizer,criterion,self.device, self.cfg.local_epochs)
  File "/home/mmaia/fedliver_v2/model/unet.py", line 163, in train
    input = input.to(device)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/torch/cuda/__init__.py", line 247, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available

The above exception was the direct cause of the following exception:

[36mray::ClientAppActor.run()[39m (pid=2974413, ip=10.50.9.88, actor_id=ff978cdf80890de43561d24801000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7f7e2816c670>)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 64, in run
    raise ClientAppException(str(ex)) from ex
flwr.client.client_app.ClientAppException: 
Exception ClientAppException occurred. Message: No CUDA GPUs are available

[2024-08-01 16:08:44,760][flwr][ERROR] - [36mray::ClientAppActor.run()[39m (pid=2974413, ip=10.50.9.88, actor_id=ff978cdf80890de43561d24801000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7f7e2816c670>)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/client/client_app.py", line 98, in __call__
    return self._call(message, context)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/client/client_app.py", line 81, in ffn
    out_message = handle_legacy_message_from_msgtype(
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/client/message_handler/message_handler.py", line 130, in handle_legacy_message_from_msgtype
    fit_res = maybe_call_fit(
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/client/client.py", line 234, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/client/numpy_client.py", line 238, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/home/mmaia/fedliver_v2/client.py", line 65, in fit
    train(self.model,self.trainloader,self.valloader,optimizer,criterion,self.device, self.cfg.local_epochs)
  File "/home/mmaia/fedliver_v2/model/unet.py", line 163, in train
    input = input.to(device)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/torch/cuda/__init__.py", line 247, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available

The above exception was the direct cause of the following exception:

[36mray::ClientAppActor.run()[39m (pid=2974413, ip=10.50.9.88, actor_id=ff978cdf80890de43561d24801000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7f7e2816c670>)
  File "/home/mmaia/my_envs/liver_torch/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 64, in run
    raise ClientAppException(str(ex)) from ex
flwr.client.client_app.ClientAppException: 
Exception ClientAppException occurred. Message: No CUDA GPUs are available
[2024-08-01 16:08:44,761][flwr][INFO] - aggregate_fit: received 0 results and 2 failures
